#include "VulkanPixelFormat.h"
#include "Rev/Core/Assert.h"

namespace Rev
{

constexpr VkFormat sVkFormatMappings[] = {
	VK_FORMAT_UNDEFINED,
	VK_FORMAT_R8_UNORM,
	VK_FORMAT_R8_UINT,
	VK_FORMAT_R8_SINT,
	VK_FORMAT_R16_UNORM,
	VK_FORMAT_R16_UINT,
	VK_FORMAT_R16_SINT,
	VK_FORMAT_R16_SFLOAT,
	VK_FORMAT_R32_UINT,
	VK_FORMAT_R32_SINT,
	VK_FORMAT_R32_SFLOAT,
	VK_FORMAT_R8G8_UNORM,
	VK_FORMAT_R16G16_UNORM,
	VK_FORMAT_R16G16_SFLOAT,
	VK_FORMAT_R32G32_SFLOAT,
	VK_FORMAT_R8G8B8_UNORM,
	VK_FORMAT_R16G16B16_UNORM,
	VK_FORMAT_R16G16B16_SFLOAT,
	VK_FORMAT_R32G32B32_UINT,
	VK_FORMAT_R32G32B32_SINT,
	VK_FORMAT_R32G32B32_SFLOAT,
	VK_FORMAT_R8G8B8A8_UNORM,
	VK_FORMAT_R8G8B8A8_SNORM,
	VK_FORMAT_R8G8B8A8_UINT,
	VK_FORMAT_R8G8B8A8_SINT,
	VK_FORMAT_R16G16B16A16_UNORM,
	VK_FORMAT_R16G16B16A16_SNORM,
	VK_FORMAT_R16G16B16A16_UINT,
	VK_FORMAT_R16G16B16A16_SINT,
	VK_FORMAT_R16G16B16A16_SFLOAT,
	VK_FORMAT_R32G32B32A32_UINT,
	VK_FORMAT_R32G32B32A32_SINT,
	VK_FORMAT_R32G32B32A32_SFLOAT,

	VK_FORMAT_D24_UNORM_S8_UINT,
	VK_FORMAT_D32_SFLOAT,

	VK_FORMAT_R8_SNORM,
	VK_FORMAT_R16_SNORM,
	VK_FORMAT_R8G8_SNORM,
	VK_FORMAT_R8G8_SINT,
	VK_FORMAT_R8G8_UINT,
	VK_FORMAT_R16G16_SNORM,
	VK_FORMAT_R16G16_SINT,
	VK_FORMAT_R16G16_UINT,
	VK_FORMAT_R32G32_SINT,
	VK_FORMAT_R32G32_UINT,

	VK_FORMAT_UNDEFINED,
	VK_FORMAT_UNDEFINED,
};


void FVulkanPixelFormat::InitPlatformFormats()
{
	//static_assert(sizeof(sVkFormatMappings) / sizeof(VkFormat) == PF_Count);
	static_assert(ARRAY_LENGTH(sVkFormatMappings) == PF_Count);

	for (uint16 i = 0; i < PF_Count; i++)
	{
		GPixelFormats[i].PlatformFormat = sVkFormatMappings[i];
		if (i >= PF_DepthStencil)
		{
			GPixelFormats[i].Supported = sVkFormatMappings[i] != VK_FORMAT_UNDEFINED;
		}
	}

}

VkFormat FVulkanPixelFormat::GetPlatformFormatSRGB(VkFormat InFormat)
{
	switch (InFormat)
	{
	case VK_FORMAT_R8_UNORM:
		return VK_FORMAT_R8_SRGB;
	case VK_FORMAT_R8G8_UNORM:
		return VK_FORMAT_R8G8_SRGB;
	case VK_FORMAT_R8G8B8_UNORM:
		return VK_FORMAT_R8G8B8_SRGB;
	case VK_FORMAT_B8G8R8_UNORM:
		return VK_FORMAT_B8G8R8_SRGB;
	case VK_FORMAT_R8G8B8A8_UNORM:
		return VK_FORMAT_R8G8B8A8_SRGB;
	case VK_FORMAT_B8G8R8A8_UNORM:
		return VK_FORMAT_B8G8R8A8_SRGB;
	case VK_FORMAT_A8B8G8R8_UNORM_PACK32:
		return VK_FORMAT_A8B8G8R8_SRGB_PACK32;
	case VK_FORMAT_BC1_RGB_UNORM_BLOCK:
		return VK_FORMAT_BC1_RGB_SRGB_BLOCK;
	case VK_FORMAT_BC1_RGBA_UNORM_BLOCK:
		return VK_FORMAT_BC1_RGBA_SRGB_BLOCK;
	case VK_FORMAT_BC2_UNORM_BLOCK:
		return VK_FORMAT_BC2_SRGB_BLOCK;
	case VK_FORMAT_BC3_UNORM_BLOCK:
		return VK_FORMAT_BC3_SRGB_BLOCK;
	case VK_FORMAT_BC7_UNORM_BLOCK:
		return VK_FORMAT_BC7_SRGB_BLOCK;
	case VK_FORMAT_ETC2_R8G8B8_UNORM_BLOCK:
		return VK_FORMAT_ETC2_R8G8B8_SRGB_BLOCK;
	case VK_FORMAT_ETC2_R8G8B8A1_UNORM_BLOCK:
		return VK_FORMAT_ETC2_R8G8B8A1_SRGB_BLOCK;
	case VK_FORMAT_ETC2_R8G8B8A8_UNORM_BLOCK:
		return VK_FORMAT_ETC2_R8G8B8A8_SRGB_BLOCK;
	case VK_FORMAT_ASTC_4x4_UNORM_BLOCK:
		return VK_FORMAT_ASTC_4x4_SRGB_BLOCK;
	case VK_FORMAT_ASTC_5x4_UNORM_BLOCK:
		return VK_FORMAT_ASTC_5x4_SRGB_BLOCK;
	case VK_FORMAT_ASTC_5x5_UNORM_BLOCK:
		return VK_FORMAT_ASTC_5x5_SRGB_BLOCK;
	case VK_FORMAT_ASTC_6x5_UNORM_BLOCK:
		return VK_FORMAT_ASTC_6x5_SRGB_BLOCK;
	case VK_FORMAT_ASTC_6x6_UNORM_BLOCK:
		return VK_FORMAT_ASTC_6x6_SRGB_BLOCK;
	case VK_FORMAT_ASTC_8x5_UNORM_BLOCK:
		return VK_FORMAT_ASTC_8x5_SRGB_BLOCK;
	case VK_FORMAT_ASTC_8x6_UNORM_BLOCK:
		return VK_FORMAT_ASTC_8x6_SRGB_BLOCK;
	case VK_FORMAT_ASTC_8x8_UNORM_BLOCK:
		return VK_FORMAT_ASTC_8x8_SRGB_BLOCK;
	case VK_FORMAT_ASTC_10x5_UNORM_BLOCK:
		return VK_FORMAT_ASTC_10x5_SRGB_BLOCK;
	case VK_FORMAT_ASTC_10x6_UNORM_BLOCK:
		return VK_FORMAT_ASTC_10x6_SRGB_BLOCK;
	case VK_FORMAT_ASTC_10x8_UNORM_BLOCK:
		return VK_FORMAT_ASTC_10x8_SRGB_BLOCK;
	case VK_FORMAT_ASTC_10x10_UNORM_BLOCK:
		return VK_FORMAT_ASTC_10x10_SRGB_BLOCK;
	case VK_FORMAT_ASTC_12x10_UNORM_BLOCK:
		return VK_FORMAT_ASTC_12x10_SRGB_BLOCK;
	case VK_FORMAT_ASTC_12x12_UNORM_BLOCK:
		return VK_FORMAT_ASTC_12x12_SRGB_BLOCK;
	case VK_FORMAT_PVRTC1_2BPP_UNORM_BLOCK_IMG:
		return VK_FORMAT_PVRTC1_2BPP_SRGB_BLOCK_IMG;
	case VK_FORMAT_PVRTC1_4BPP_UNORM_BLOCK_IMG:
		return VK_FORMAT_PVRTC1_4BPP_SRGB_BLOCK_IMG;
	case VK_FORMAT_PVRTC2_2BPP_UNORM_BLOCK_IMG:
		return VK_FORMAT_PVRTC2_2BPP_SRGB_BLOCK_IMG;
	case VK_FORMAT_PVRTC2_4BPP_UNORM_BLOCK_IMG:
		return VK_FORMAT_PVRTC2_4BPP_SRGB_BLOCK_IMG;
	default:
		break;
	}

	return InFormat;
}

}


